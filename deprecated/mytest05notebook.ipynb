{
 "cells": [
  {
   "cell_type": "code",
   "id": "8bee008a55469b64",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import glob\n",
    "import os\n",
    "import scripts\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# import odvae\n",
    "\n",
    "from diffusers import StableDiffusionPipeline, AutoencoderKL\n",
    "from diffusers import UNet2DConditionModel\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T06:53:21.225502Z",
     "start_time": "2024-10-20T06:53:20.648671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "diffusion_model_id = \"./checkpoints/stable-diffusion-v1-5\"\n",
    "vae = AutoencoderKL.from_pretrained(diffusion_model_id, subfolder=\"vae\")\n",
    "unet = UNet2DConditionModel.from_pretrained(diffusion_model_id, subfolder=\"unet\")\n",
    "\n",
    "# Print the VAE model structure\n",
    "print(vae)"
   ],
   "id": "cc88357da97ae1ca",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T03:14:42.589145Z",
     "start_time": "2024-10-19T03:14:42.569494Z"
    }
   },
   "cell_type": "code",
   "source": "print(unet)",
   "id": "initial_id",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T03:14:43.390114Z",
     "start_time": "2024-10-19T03:14:43.349311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# VAE整体结构\n",
    "for name, module in vae.named_modules():\n",
    "    print(f\"{name}: {module}\")"
   ],
   "id": "36c746950ac40ccf",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T03:14:44.153869Z",
     "start_time": "2024-10-19T03:14:44.145576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder = vae.encoder\n",
    "decoder = vae.decoder\n",
    "\n",
    "# Print the encoder structure\n",
    "print(encoder)"
   ],
   "id": "a66592eee7882318",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T03:14:44.830593Z",
     "start_time": "2024-10-19T03:14:44.821451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the decoder structure\n",
    "print(decoder)"
   ],
   "id": "2bd5237ce8150a17",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T03:14:46.878214Z",
     "start_time": "2024-10-19T03:14:45.353941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 载入lora weights，打印观察结构\n",
    "# lora_model_id = \"./checkpoints/georgefen-AquaLoRA-Models/models--georgefen--AquaLoRA-Models/snapshots/98688b2a1e762339593ee8fe96ed13762f06b732/ppft_trained/101010101010101010101010101010101010101010101010/pytorch_lora_weights.safetensors\"\n",
    "lora_model_id = \"../checkpoints/pytorch_lora_weights.safetensors\"\n",
    "lora = AutoencoderKL.from_pretrained(lora_model_id, device_map=\"auto\",\n",
    "                                     low_cpu_mem_usage=True,\n",
    "                                     use_safetensors=True)\n",
    "print(lora)"
   ],
   "id": "95df668f4c023cd3",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T03:14:47.923815Z",
     "start_time": "2024-10-19T03:14:47.514038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 这个是合并了水印的lora模型\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "filename = \"../checkpoints/pytorch_lora_weights.safetensors\"\n",
    "model = load_file(filename)\n",
    "state_dict = model\n",
    "for key, value in model.items():\n",
    "    print(key, value)\n"
   ],
   "id": "f965c1b423d4948a",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:07:50.796544Z",
     "start_time": "2024-10-22T14:07:50.274651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 这个是没有合并水印的lora模型的结构\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "filename = \"./checkpoints/pytorch_lora_weights_origin.safetensors\"\n",
    "model = load_file(filename)\n",
    "no_watermarked_state_dict = model\n",
    "for key, value in model.items():\n",
    "    print(\"\\nkey:\", key, \"\\nvalue:\", value)"
   ],
   "id": "b49b31523eabbfcb",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T03:14:53.312879Z",
     "start_time": "2024-10-19T03:14:53.298391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 合并水印的lora模型的结构\n",
    "print(\"\\nSummary of LoRA weights:\")\n",
    "lora_num_layers = {}\n",
    "lora_layer_shapes = {}\n",
    "for key, value in state_dict.items():\n",
    "    layer_name = key.split('.')[0]\n",
    "    if layer_name not in lora_num_layers:\n",
    "        lora_num_layers[layer_name] = 0\n",
    "        lora_layer_shapes[layer_name] = []\n",
    "    lora_num_layers[layer_name] += 1\n",
    "    lora_layer_shapes[layer_name].append(value.shape)\n",
    "\n",
    "for layer, count in lora_num_layers.items():\n",
    "    print(f\"Layer: {layer}, Number of parameters: {count}, Shapes: {lora_layer_shapes[layer]}\")\n"
   ],
   "id": "672a1b4ef43343d4",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T03:14:54.291788Z",
     "start_time": "2024-10-19T03:14:54.281334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 没有合并水印的lora模型的结构\n",
    "print(\"\\nSummary of no-watermarked LoRA weights:\")\n",
    "no_watermarked_lora_num_layers = {}\n",
    "no_watermarked_lora_layer_shapes = {}\n",
    "for key, value in no_watermarked_state_dict.items():\n",
    "    layer_name = key.split('.')[0]\n",
    "    if layer_name not in no_watermarked_lora_num_layers:\n",
    "        no_watermarked_lora_num_layers[layer_name] = 0\n",
    "        no_watermarked_lora_layer_shapes[layer_name] = []\n",
    "    no_watermarked_lora_num_layers[layer_name] += 1\n",
    "    no_watermarked_lora_layer_shapes[layer_name].append(value.shape)\n",
    "\n",
    "for layer, count in no_watermarked_lora_num_layers.items():\n",
    "    print(f\"Layer: {layer}, Number of parameters: {count}, Shapes: {no_watermarked_lora_layer_shapes[layer]}\")"
   ],
   "id": "e319423c236f9b30",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T03:14:55.906967Z",
     "start_time": "2024-10-19T03:14:55.898374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 比较没有合并水印的lora模型的结构和合并了的的每一个layer参数格式是否一致\n",
    "if no_watermarked_lora_layer_shapes['unet'] == lora_layer_shapes['unet']:\n",
    "    print(\"The layer shapes are the same.\")\n"
   ],
   "id": "76bef55412fff89b",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T03:14:57.283973Z",
     "start_time": "2024-10-19T03:14:57.267864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nSummary of LoRA weights:\")\n",
    "num_blocks = {}\n",
    "block_shapes = {}\n",
    "\n",
    "# 遍历 state_dict 中的所有键\n",
    "for key, value in state_dict.items():\n",
    "    # 分割键来提取具体 block 的信息，通常结构是 'layer.block.subblock.weight'\n",
    "    # 我们将前两个部分(layer 和 block)组合起来作为 block 的名称\n",
    "    block_name = '.'.join(key.split('.')[:3])  # 提取 'layer.block.subblock' 名称\n",
    "    if block_name not in num_blocks:\n",
    "        num_blocks[block_name] = 0\n",
    "        block_shapes[block_name] = []\n",
    "\n",
    "    # 记录每个 block 的参数数量和 shape\n",
    "    num_blocks[block_name] += 1\n",
    "    block_shapes[block_name].append(value.shape)\n",
    "\n",
    "# 输出每个 block 的信息\n",
    "for block, count in num_blocks.items():\n",
    "    print(f\"Block: {block}, Number of parameters: {count}, Shapes: {block_shapes[block]}\")\n"
   ],
   "id": "1825b4dfc49c485a",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T03:14:58.828755Z",
     "start_time": "2024-10-19T03:14:58.802894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nLoRA 权重的结构信息：\")\n",
    "\n",
    "num_blocks = {}  # 用于存储每个 block 的信息\n",
    "layer_type_count = {}  # 用于存储每种层的数量\n",
    "shape_analysis = {}  # 用于存储每种层的 shape 信息\n",
    "# 遍历 state_dict 中的所有键\n",
    "for key, value in state_dict.items():\n",
    "    # 将键按照 '.' 分割\n",
    "    key_parts = key.split('.')\n",
    "\n",
    "    # 定义 block 的层级，例如到 'unet.down_blocks.0.attentions.0'\n",
    "    block_level = 5  # 根据模型的具体结构，选择哪几个.分割的部分作为 block 的名称\n",
    "    block_name = '.'.join(key_parts[:block_level])  # 提取 block 的名称\n",
    "\n",
    "    # 定义 layer_name 为剩余部分\n",
    "    layer_name = '.'.join(key_parts[block_level:])\n",
    "\n",
    "    # 初始化 block 的信息\n",
    "    if block_name not in num_blocks:\n",
    "        num_blocks[block_name] = {}\n",
    "\n",
    "    # 记录每个 block 下的层信息\n",
    "    if layer_name not in num_blocks[block_name]:\n",
    "        num_blocks[block_name][layer_name] = []\n",
    "    num_blocks[block_name][layer_name].append(value.shape)\n",
    "\n",
    "    # 统计每种 layer 类型出现的次数\n",
    "    layer_type = '.'.join(key_parts[block_level:-1])  # 去掉最后的 weight\n",
    "\n",
    "    if layer_type not in layer_type_count:\n",
    "        layer_type_count[layer_type] = 0\n",
    "    layer_type_count[layer_type] += 1\n",
    "\n",
    "    # 记录每种层的 shape 信息\n",
    "    if layer_type not in shape_analysis:\n",
    "        shape_analysis[layer_type] = []\n",
    "    shape_analysis[layer_type].append(value.shape)\n",
    "\n",
    "# 输出每个 block 和其下的层信息\n",
    "for block, layers in num_blocks.items():\n",
    "    print(f\"\\nBlock: {block}\")\n",
    "    for layer, shapes in layers.items():\n",
    "        print(f\"  Layer: {layer}, Shapes: {shapes}\")\n"
   ],
   "id": "c220bd5cb0656abd",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T03:15:00.464948Z",
     "start_time": "2024-10-19T03:15:00.455317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 输出层类型统计信息\n",
    "print(\"\\nLoRA 层类型统计信息：\")\n",
    "for layer_type, count in layer_type_count.items():\n",
    "    print(f\"  Layer type: {layer_type}, Count: {count}\")"
   ],
   "id": "a40fd40f5ae849d",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T03:15:01.909503Z",
     "start_time": "2024-10-19T03:15:01.899387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 输出层形状分析信息\n",
    "print(\"\\nLoRA 层的形状分析：\")\n",
    "for layer_type, shapes in shape_analysis.items():\n",
    "    unique_shapes = set(shapes)  # 统计唯一的 shape\n",
    "    print(f\"  Layer type: {layer_type}, Unique Shapes: {unique_shapes}\")"
   ],
   "id": "99db63a12b15e55b",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "  Layer type: lora.down, Unique Shapes: {torch.Size([320, 1280, 1, 1])}\n",
    "  Layer type: lora.up, Unique Shapes: {torch.Size([1280, 320, 1, 1])}\n",
    "是什么?\n",
    "是mid_block的proj_in和proj_out的shape"
   ],
   "id": "a4d595d38bc5247b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:05:56.551611Z",
     "start_time": "2024-10-22T14:05:56.533365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练获取一定数量的lora模型作为我们的训练数据\n",
    "dataset_path = \"./checkpoints/lora_weights_dataset\"\n",
    "\n",
    "# TODO\n"
   ],
   "id": "333f011abc015276",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:10:22.277795Z",
     "start_time": "2024-10-22T14:08:02.771923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_path = \"./checkpoints/lora_weights_dataset/rank320_batchsz8_gpu4\"\n",
    "original_lora_param_info = {}\n",
    "# original_lora_data_lengths = []\n",
    "for file in glob.glob(os.path.join(dataset_path, \"*.safetensors\")):\n",
    "    model = load_file(file)\n",
    "    for key, value in model.items():\n",
    "        param_info = {\n",
    "            'shape': value.shape,\n",
    "            'length': value.numel()\n",
    "        }\n",
    "        original_lora_param_info[key] = param_info"
   ],
   "id": "dccdd98d453d3abc",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:12:46.365462Z",
     "start_time": "2024-10-22T14:12:46.354479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "idx = 0\n",
    "for layer_name, param_info in original_lora_param_info.items():\n",
    "    idx += 1\n",
    "    print(f\"Layer: {layer_name}, Shape: {param_info['shape']}, Length: {param_info['length']}\\n\")\n",
    "    if idx == 20:\n",
    "        break\n"
   ],
   "id": "bb205024f0ef7d02",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T14:39:34.762826Z",
     "start_time": "2024-10-22T14:16:45.523550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 对获取的lora模型权重进行预处理，将其转换为我们需要的格式\n",
    "# TODO: 之后可能需要改成batch的形式\n",
    "total_lora_data = []\n",
    "for file in glob.glob(os.path.join(dataset_path, \"*.safetensors\")):\n",
    "    single_lora_weights = []\n",
    "    model = load_file(file)\n",
    "    for key, value in model.items():\n",
    "        # 临时代码，打印观察 TODO:删除\n",
    "        # print(\"value: \")\n",
    "        # print(value)\n",
    "        # 对每个value进行Z-score标准化的策略\n",
    "        mean = value.mean()\n",
    "        std = value.std()\n",
    "        value = (value - mean) / std\n",
    "\n",
    "        # 将value展平为一维\n",
    "        flattened_value = value.flatten()\n",
    "        single_lora_weights.append(flattened_value)\n",
    "        # print(\"flattened_value：\")\n",
    "        # print(flattened_value)\n",
    "    single_lora_weights = torch.cat(single_lora_weights, dim=0)\n",
    "    # total_lora_data.append(single_lora_weights)\n",
    "    torch.save(single_lora_weights,\n",
    "               os.path.join(dataset_path, \"normalized_{}.pth\".format(os.path.basename(file).split(\".\")[0])))\n",
    "    # torch.save(total_lora_data, \"./checkpoints/lora_data.pth\")"
   ],
   "id": "2b3d1bc4d48c874f",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T03:15:27.789277Z",
     "start_time": "2024-10-19T03:15:27.772003Z"
    }
   },
   "cell_type": "code",
   "source": "total_lora_data[0].shape",
   "id": "7eab056ef78f5b43",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T03:15:31.648850Z",
     "start_time": "2024-10-19T03:15:31.633128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 试着重建展平的lora权重回原来的形状\n",
    "# 重建模型的字典\n",
    "start = 0\n",
    "reconstructed_lora_weights = {}\n",
    "for layer_name, param_info in original_lora_param_info.items():\n",
    "    # 在lora权重中，key为layer_name代表某一层的名字，param_info['length']代表这一层的参数个数, param_info['shape']代表这一层参数的shape\n",
    "    # 从total_lora_data中取出这一层的参数\n",
    "    end = start + param_info['length']\n",
    "    layer_weight_vector = total_lora_data[0][start:end]\n",
    "    layer_weight_matrix = layer_weight_vector.view(param_info['shape'])\n",
    "    reconstructed_lora_weights[layer_name] = layer_weight_matrix\n",
    "    start = end\n",
    "\n"
   ],
   "id": "7fb1d08859863239",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T03:15:32.532668Z",
     "start_time": "2024-10-19T03:15:32.199764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 打印观察重建的lora权重\n",
    "for layer_name, layer_weight in reconstructed_lora_weights.items():\n",
    "    print(f\"Layer: {layer_name}, Shape: {layer_weight.shape}\")\n",
    "    print(layer_weight)"
   ],
   "id": "5b3636437c38f4ff",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "观察发现重建的结果一致，此方法可行。\n",
    "2024/10/15 22:20更新: 找到了论文的代码，方法和我一样"
   ],
   "id": "5b522f4956df0066"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T04:16:34.370745Z",
     "start_time": "2024-10-19T04:16:29.146263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class ParameterVectorDataset(Dataset):\n",
    "    def __init__(self, data_paths):\n",
    "        self.data_paths = data_paths  # 数据文件的路径列表\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 加载第 idx 个参数向量\n",
    "        data = torch.load(self.data_paths[idx])\n",
    "        return data"
   ],
   "id": "1f4a8637aadb570a",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T04:16:59.845547Z",
     "start_time": "2024-10-19T04:16:59.828508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 如果保存模型检查点的目录不存在，则创建\n",
    "checkpoint_dir = \"./checkpoints/lora_vae_checkpoints\"\n",
    "if not os.path.isdir(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "    \n",
    "# 如果保存模型日志的目录不存在，则创建\n",
    "log_dir = \"./logs/lora_vae_logs\"\n",
    "if not os.path.isdir(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "writer = SummaryWriter(log_dir)"
   ],
   "id": "5c226936e60c162b",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T04:17:00.869343Z",
     "start_time": "2024-10-19T04:17:00.861590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 示例数据加载（请替换为您的数据加载逻辑）\n",
    "# 生成随机数据作为示例\n",
    "batch_size = 2\n",
    "num_samples = 100  # 请根据您的数据量调整\n",
    "in_dim = 135659520  # 请根据您的数据维度调整"
   ],
   "id": "50256b4f5ec9faf3",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T04:17:05.128488Z",
     "start_time": "2024-10-19T04:17:05.119595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_path = \"./checkpoints/lora_weights_dataset\"\n",
    "\n",
    "rand_val_dataset_path = os.path.join(dataset_path, \"rand_val\")\n",
    "rand_test_dataset_path = os.path.join(dataset_path, \"rand_test\")"
   ],
   "id": "92580677579b78bf",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "\n",
    "# 随机生成100个样本，每个样本的维度为 135659520，值的区间为[-1,+1]，并分别保存在 rand_test_normalized_data1.pth, rand_test_normalized_data2.pth, ..., rand_test_normalized_data100.pth 中\n",
    "for i in range(num_samples):\n",
    "    data = torch.rand(in_dim) * 2 - 1\n",
    "    torch.save(data, os.path.join(rand_test_dataset_path, f\"rand_test_normalized_data{i + 1}.pth\"))\n"
   ],
   "id": "f53cb40c2e3b89e2",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T10:35:17.781677Z",
     "start_time": "2024-10-18T10:30:15.727557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 生成随机的评估数据\n",
    "# 随机生成100个样本，每个样本的维度为 135659520，值的区间为[-1,+1]，并分别保存在 rand_val_normalized_data1.pth, rand_val_normalized_data2.pth, ..., rand_val_normalized_data100.pth 中\n",
    "\n",
    "for i in range(num_samples):\n",
    "    data = torch.rand(in_dim) * 2 - 1\n",
    "    torch.save(data, os.path.join(rand_val_dataset_path, f\"rand_val_normalized_data{i + 1}.pth\"))"
   ],
   "id": "3d3aa44c228f3037",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T04:17:10.984704Z",
     "start_time": "2024-10-19T04:17:10.972331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 随机测试数据文件列表\n",
    "rand_test_data_paths = glob.glob(os.path.join(rand_test_dataset_path,\"rand_test_normalized_data*.pth\"))\n",
    "# 创建数据集\n",
    "rand_test_data_sets = ParameterVectorDataset(rand_test_data_paths)\n",
    "# 创建数据加载器\n",
    "rand_test_data_loader = DataLoader(rand_test_data_sets, batch_size=batch_size, shuffle=True, num_workers=2)\n"
   ],
   "id": "bafc47d5de16105e",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T04:17:12.519722Z",
     "start_time": "2024-10-19T04:17:12.500733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 随机评估数据文件列表\n",
    "rand_val_data_paths = glob.glob(os.path.join(rand_val_dataset_path, \"rand_val_normalized_data*.pth\"))\n",
    "rand_val_data_paths"
   ],
   "id": "47c06090c3b5a387",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T04:17:13.964977Z",
     "start_time": "2024-10-19T04:17:13.956503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 创建数据集\n",
    "rand_val_data_sets = ParameterVectorDataset(rand_val_data_paths)\n",
    "# 创建数据加载器\n",
    "rand_val_data_loader = DataLoader(rand_val_data_sets, batch_size=batch_size, shuffle=True, num_workers=2)\n"
   ],
   "id": "de201c418a7f543a",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T04:17:17.484770Z",
     "start_time": "2024-10-19T04:17:17.473174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 训练数据文件列表\n",
    "train_data_paths = glob.glob(os.path.join(dataset_path, \"normalized_*.pth\"))\n",
    "# 创建数据集\n",
    "train_data_sets = ParameterVectorDataset(train_data_paths)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_data_loader = DataLoader(train_data_sets, batch_size=batch_size, shuffle=True, num_workers=2)"
   ],
   "id": "b5f7d014709db5c1",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T04:17:28.426433Z",
     "start_time": "2024-10-19T04:17:28.390007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from tqdm import tqdm\n",
    "# from torch.cuda.amp import GradScaler, autocast\n",
    "# from accelerate import Accelerator\n",
    "# import torch\n",
    "# import os\n",
    "# # 试着将重建的lora权重加载到odvae模型中\n",
    "# from odvae import ODVAE, medium, small\n",
    "# \n",
    "# # 设置模型参数\n",
    "# latent_dim = 12\n",
    "# kld_weight = 0.005\n",
    "# in_dim = 2048  # 请确保 in_dim 设置正确\n",
    "# \n",
    "# # 使用 Accelerator 进行多卡训练\n",
    "# accelerator = Accelerator()\n",
    "# \n",
    "# # 初始化模型\n",
    "# ODVAE_model = medium(in_dim=in_dim, latent_dim=latent_dim, kld_weight=kld_weight)\n",
    "# \n",
    "# # 设置优化器\n",
    "# optimizer = torch.optim.Adam(ODVAE_model.parameters(), lr=1e-3, weight_decay=2e-6)\n",
    "# \n",
    "# # 初始化最佳验证损失\n",
    "# best_val_loss = float('inf')\n",
    "# \n",
    "# # 定义学习率调度器\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
    "#                                                        factor=0.5, patience=10,\n",
    "#                                                        verbose=True, min_lr=1e-6)\n",
    "# \n",
    "# # 定义早停参数\n",
    "# early_stopping_patience = 20\n",
    "# early_stopping_counter = 0\n",
    "# \n",
    "# # 定义训练参数\n",
    "# num_epochs = 30000\n",
    "# batch_size = 4\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from accelerate import Accelerator\n",
    "import torch\n",
    "import os\n",
    "# 试着将重建的lora权重加载到odvae模型中\n",
    "from odvae import ODVAE, medium, small\n",
    "\n",
    "# 设置模型参数\n",
    "latent_dim = 256\n",
    "kld_weight = 0.005\n",
    "in_dim = 135659520  # 请确保 in_dim 设置正确\n",
    "\n",
    "# 使用 Accelerator 进行多卡训练\n",
    "accelerator = Accelerator()\n",
    "def free_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "# 初始化模型\n",
    "ODVAE_model = medium(in_dim=in_dim, latent_dim=latent_dim, kld_weight=kld_weight)\n",
    "\n",
    "# 设置优化器\n",
    "optimizer = torch.optim.Adam(ODVAE_model.parameters(), lr=1e-3, weight_decay=2e-6)\n",
    "\n",
    "# 初始化最佳验证损失\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# 定义学习率调度器\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
    "                                                       factor=0.5, patience=10,\n",
    "                                                       verbose=True, min_lr=1e-6)\n",
    "\n",
    "# 定义早停参数\n",
    "early_stopping_patience = 20\n",
    "early_stopping_counter = 0\n",
    "\n",
    "# 定义训练参数\n",
    "num_epochs = 30000\n",
    "# batch_size = 2"
   ],
   "id": "9673bd3e4eb74e17",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T04:18:12.645215Z",
     "start_time": "2024-10-19T04:17:34.579088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for epoch in range(num_epochs):\n",
    "#     ODVAE_model.train()\n",
    "#     epoch_loss = 0.0\n",
    "#     \n",
    "#     rand_test_loader_tqdm = tqdm(rand_test_data_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Train\", leave=False)\n",
    "# \n",
    "#     \n",
    "#     for batch_idx, batch in enumerate(rand_test_loader_tqdm):\n",
    "#         x = batch  # x 的形状为 [batch_size, 135659520]\n",
    "#         x = x.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         # with autocast():\n",
    "#         # 前向传播\n",
    "#         outputs = ODVAE_model(x)\n",
    "#         loss = outputs['loss']\n",
    "#         # 反向传播和优化\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         \n",
    "#         epoch_loss += loss.item()\n",
    "#         writer.add_scalar('Train/Loss', loss.item(), epoch * len(rand_test_data_loader) + batch_idx)\n",
    "#     avg_test_loss = epoch_loss / len(rand_test_data_loader)\n",
    "#     \n",
    "#     # 验证阶段\n",
    "#     ODVAE_model.eval()\n",
    "#     val_loss = 0.0\n",
    "#     rand_val_loader_tqdm = tqdm(rand_val_data_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\", leave=False)\n",
    "# \n",
    "#     \n",
    "#     with torch.no_grad():\n",
    "#         for batch_idx, batch in enumerate(rand_val_loader_tqdm):\n",
    "#             x = batch  # x 的形状为 [batch_size, 135659520]\n",
    "#             x = x.to(device)\n",
    "#             outputs = ODVAE_model(x)\n",
    "#             loss = outputs['loss']\n",
    "#             val_loss += loss.item()\n",
    "#     avg_val_loss = val_loss / len(rand_val_data_loader)\n",
    "#     print(f'Avg Validation Loss: {avg_val_loss:.4f}')\n",
    "#         \n",
    "#     scheduler.step(avg_val_loss)\n",
    "#     writer.add_scalar('AvgLoss/Train', avg_test_loss, epoch)\n",
    "#     writer.add_scalar('AvgLoss/Validation', avg_val_loss, epoch)\n",
    "#     print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_test_loss:.4f}')\n",
    "# \n",
    "#     # 记录学习率\n",
    "#     current_lr = optimizer.param_groups[0]['lr']\n",
    "#     writer.add_scalar('Learning_Rate', current_lr, epoch)\n",
    "# \n",
    "#         # 检查验证损失是否降低\n",
    "#     if avg_val_loss < best_val_loss:\n",
    "#         best_val_loss = avg_val_loss\n",
    "#         early_stopping_counter = 0  # 重置早停计数器\n",
    "#         # 保存最佳模型\n",
    "#         checkpoint_path = os.path.join(checkpoint_dir, 'best_model.pth')\n",
    "#         torch.save(ODVAE_model.state_dict(), checkpoint_path)\n",
    "#         print(f'Best ODVAE_model saved at epoch {epoch+1} with validation loss {best_val_loss:.4f}')\n",
    "#     else:\n",
    "#         early_stopping_counter += 1\n",
    "#         if early_stopping_counter >= early_stopping_patience:\n",
    "#             print(f'Early stopping at epoch {epoch+1}')\n",
    "#             break\n",
    "# \n",
    "#     # 打印当前 epoch 的训练和验证损失\n",
    "#         \n",
    "#     if (epoch + 1) % 1000 == 0:\n",
    "#         checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch+1}.pth')\n",
    "#         torch.save(ODVAE_model.state_dict(), checkpoint_path)\n",
    "#         print(f'ODVAE_model checkpoint saved at epoch {epoch+1}')\n",
    "#         \n",
    "# writer.close()\n",
    "# 使用 Accelerator 包装模型、优化器和数据加载器\n",
    "ODVAE_model, optimizer, rand_test_data_loader, rand_val_data_loader = accelerator.prepare(\n",
    "    ODVAE_model, optimizer, rand_test_data_loader, rand_val_data_loader\n",
    ")\n",
    "\n",
    "# 开始训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    ODVAE_model.train()\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    rand_test_loader_tqdm = tqdm(rand_test_data_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Train\", leave=False)\n",
    "\n",
    "    for batch_idx, batch in enumerate(rand_test_loader_tqdm):\n",
    "        x = batch  # x 的形状为 [batch_size, 135659520]\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with accelerator.autocast():\n",
    "            # 前向传播\n",
    "            outputs = ODVAE_model(x)\n",
    "            loss = outputs['loss']\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        if accelerator.is_main_process:\n",
    "            writer.add_scalar('Train/Loss', loss.item(), epoch * len(rand_test_data_loader) + batch_idx)\n",
    "\n",
    "        # 释放未使用的显存\n",
    "        free_memory()\n",
    "    avg_test_loss = epoch_loss / len(rand_test_data_loader)\n",
    "\n",
    "    # 验证阶段\n",
    "    ODVAE_model.eval()\n",
    "    val_loss = 0.0\n",
    "    rand_val_loader_tqdm = tqdm(rand_val_data_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(rand_val_loader_tqdm):\n",
    "            x = batch  # x 的形状为 [batch_size, 135659520]\n",
    "            with accelerator.autocast():\n",
    "                outputs = ODVAE_model(x)\n",
    "                loss = outputs['loss']\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(rand_val_data_loader)\n",
    "    if accelerator.is_main_process:\n",
    "        print(f'Avg Validation Loss: {avg_val_loss:.4f}')\n",
    "        scheduler.step(avg_val_loss)\n",
    "        writer.add_scalar('AvgLoss/Train', avg_test_loss, epoch)\n",
    "        writer.add_scalar('AvgLoss/Validation', avg_val_loss, epoch)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_test_loss:.4f}')\n",
    "\n",
    "    # 记录学习率\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    if accelerator.is_main_process:\n",
    "        writer.add_scalar('Learning_Rate', current_lr, epoch)\n",
    "\n",
    "    # 检查验证损失是否降低\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        early_stopping_counter = 0  # 重置早停计数器\n",
    "        # 保存最佳模型\n",
    "        if accelerator.is_main_process:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, 'best_model.pth')\n",
    "            accelerator.save(ODVAE_model.state_dict(), checkpoint_path)\n",
    "            print(f'Best ODVAE_model saved at epoch {epoch+1} with validation loss {best_val_loss:.4f}')\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= early_stopping_patience:\n",
    "            if accelerator.is_main_process:\n",
    "                print(f'Early stopping at epoch {epoch+1}')\n",
    "            break\n",
    "\n",
    "    # 打印当前 epoch 的训练和验证损失\n",
    "    if (epoch + 1) % 1000 == 0 and accelerator.is_main_process:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch+1}.pth')\n",
    "        accelerator.save(ODVAE_model.state_dict(), checkpoint_path)\n",
    "        print(f'ODVAE_model checkpoint saved at epoch {epoch+1}')\n",
    "\n",
    "if accelerator.is_main_process:\n",
    "    writer.close()"
   ],
   "id": "7c721fac12e13171",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "680c9e200a43c353",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
